{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.models import load_model,save_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from matplotlib.patches import Rectangle\n",
    "import os\n",
    "from scipy.misc import imsave\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import xception\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, Adam,Adagrad\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from math import sqrt\n",
    "from keras.callbacks import History \n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import xception\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense,Input\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.activations import relu\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from math import sqrt\n",
    "from keras.callbacks import History \n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_dir = '/home/roshansanthosh/Documents/YOLO/YOLO/MultiClass'\n",
    "\n",
    "base_dir = '/home/rsk/Documents/Projects/YOLO/MultiClass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def read_img(filepath, size):\n",
    "    img = image.load_img((filepath), target_size=size)\n",
    "    img = image.img_to_array(img,data_format='channels_last')\n",
    "    return img\n",
    "\n",
    "os.chdir(base_dir + '/25x25/')\n",
    "\n",
    "X = []\n",
    "\n",
    "for i in range(8000):\n",
    "    img = read_img(str(i)+'.png',(25,25))\n",
    "    X.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "truth = pd.read_csv('25x25_truth.csv')\n",
    "y = np.array(truth)\n",
    "y = np.array(y[:,1:])\n",
    "\n",
    "\n",
    "X= np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size=25\n",
    "\n",
    "\n",
    "trainX = X[:7000,:,:,:]\n",
    "trainy = y[:7000,:]\n",
    "\n",
    "testX = X[7000:,:,:,:]\n",
    "testy = y[7000:,:]\n",
    "\n",
    "train_generator = train_datagen.flow(x=trainX,y=trainy,batch_size=batch_size)\n",
    "test_generator = test_datagen.flow(x=testX,y=testy,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  0  1 16  1  0  6  5  2  3  1  0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 20\n",
    "\n",
    "plt.imshow(X[i])\n",
    "\n",
    "print(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxLimits = [[0,0,12,25],\n",
    "             [12,0,25,25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    The bb_interesection functions in the earlier test cases varies slightly from this.\n",
    "    The previous version took 4 arguments : top left x, top left y, bottom right x, bottom right y\n",
    "    This version takes 4 arguments : top left x, top left y, width, height\n",
    "    \n",
    "'''\n",
    "    \n",
    "def bb_intersection_over_union(boxA, boxB):\n",
    "\t# determine the (x, y)-coordinates of the intersection rectangle\n",
    "\txA = max(boxA[0], boxB[0])\n",
    "\tyA = max(boxA[1], boxB[1])\n",
    "\txB = min(boxA[0] + boxA[2],boxB[0] + boxB[2])\n",
    "\tyB = min(boxA[1] + boxA[3],boxB[1] + boxB[3])\n",
    " \n",
    "\t# compute the area of intersection rectangle\n",
    "\tinterArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    " \n",
    "\t# compute the area of both the prediction and ground-truth\n",
    "\t# rectangles\n",
    "\tboxAArea = (boxA[2] + 1) * (boxA[3] + 1)\n",
    "\tboxBArea = (boxB[2] + 1) * (boxB[3] + 1)\n",
    " \n",
    "\t# compute the intersection over union by taking the intersection\n",
    "\t# area and dividing it by the sum of prediction + ground-truth\n",
    "\t# areas - the interesection area\n",
    "\tiou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "\t# return the intersection over union value\n",
    "\treturn iou\n",
    "\n",
    "\n",
    "\n",
    "def getIoU(model,testData,testTruth,numAnchors = 2,rescale=True):\n",
    "    \n",
    "    anchorLength = int(testTruth[0].shape[0]/numAnchors)\n",
    " \n",
    "    \n",
    "    sample = testData\n",
    "    if rescale==True:\n",
    "        sample = testData/255.\n",
    "    preds = model.predict(sample)\n",
    "    \n",
    "    IoUSum = 0.0\n",
    "    for i in range(len(testTruth)):\n",
    "        iouTotal = 0.0\n",
    "        for j in range(0,len(testTruth[i]),anchorLength):\n",
    "            truth = testTruth[i][j:(j+4)]\n",
    "            pred  =  preds[i][j:(j+4)]\n",
    "            iouTotal += bb_intersection_over_union(truth,pred)\n",
    "        \n",
    "        IoUSum += iouTotal/numAnchors\n",
    "    \n",
    "    meanIoU = IoUSum/len(testTruth)\n",
    "    \n",
    "    return(meanIoU)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanFolder(buildNo,keep=5):\n",
    "    \n",
    "    os.chdir(base_dir + '/Models')\n",
    "    fileList = os.listdir('./')\n",
    "    \n",
    "    selectFileList = []\n",
    "    for filename in fileList:\n",
    "        if str(buildNo) in filename.split(\"_\"):\n",
    "            selectFileList.append(filename)\n",
    "            \n",
    "    a = []\n",
    "    for i in selectFileList:\n",
    "        val = float(i[:-5].split(\"_\")[3])\n",
    "        a.append([val,i])\n",
    "        \n",
    "    a = sorted(a,key=lambda x : x[0])\n",
    "    \n",
    "    keep = min(keep,len(a))\n",
    "    \n",
    "    keepList = [i[1] for i in a[:keep]]\n",
    "    dropList = [i[1] for i in a[keep:]]\n",
    "    \n",
    "    for filename in dropList:\n",
    "        os.remove(filename)\n",
    "            \n",
    "    return(keepList)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(model,epochs,build=1,optimizer = 'adagrad',keep=5,use_lr=True):\n",
    "    \n",
    "        os.chdir(base_dir)\n",
    "        \n",
    "        \n",
    "        sgd = SGD(lr=1 * 1e-1, momentum=0.9, nesterov=True)\n",
    "        adam = Adam(lr=2 * 1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    \n",
    "        model.compile(loss='mean_squared_error',optimizer=optimizer,metrics=['mse'])\n",
    "        hist = History()\n",
    "        checkPoint = ModelCheckpoint(filepath='./Models/model_'+str(build)+'_{epoch:02d}_{val_loss:.4f}.hdf5',verbose=1,save_best_only=True,mode=min)\n",
    "#         tensorboard = keras.callbacks.TensorBoard(log_dir='./logs/{}'.format(build), histogram_freq=0, batch_size=25, write_graph=True, write_grads=False, write_images=False)\n",
    "#         lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=1e-5, patience=3, verbose=1)\n",
    "    \n",
    "        if use_lr == True:\n",
    "            lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.1, epsilon=1e-5, patience=3, verbose=1)\n",
    "            model.fit_generator(train_generator,epochs=epochs,validation_data=test_generator,callbacks = [hist,checkPoint,lr_reduce],verbose=0)\n",
    "        else:\n",
    "            model.fit_generator(train_generator,epochs=epochs,validation_data=test_generator,callbacks = [hist,checkPoint],verbose=0)\n",
    "            \n",
    "        \n",
    "        \n",
    "        keepList = cleanFolder(build,keep=keep)\n",
    "        \n",
    "        print(\"Results\")\n",
    "        \n",
    "        for filename in keepList:\n",
    "            print(filename)\n",
    "            model = load_model(filename)\n",
    "            epoch = filename.split(\"_\")[2]\n",
    "            mse = filename.split(\"_\")[3]\n",
    "            IoU = round(getIoU(model,testX,testy,numAnchors=2),3)\n",
    "            print(\"Epoch : {} MSE : {} IoU : {}\".format(epoch,mse,IoU))\n",
    "        \n",
    "        del model\n",
    "        del hist\n",
    "        del checkPoint\n",
    "#         del tensorboard\n",
    "        del keepList\n",
    "        gc.collect()\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Run Iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(BatchNormalization(input_shape=(25,25,3)))\n",
    "model.add(Conv2D(128, (3,3),activation='relu', data_format='channels_last'))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(64, (3,3),activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(12, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.08159, saving model to ./Models/model_1_01_0.0816.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.08159 to 0.05857, saving model to ./Models/model_1_02_0.0586.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.05857 to 0.04662, saving model to ./Models/model_1_03_0.0466.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04662 to 0.04234, saving model to ./Models/model_1_04_0.0423.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04234 to 0.03985, saving model to ./Models/model_1_05_0.0398.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03985 to 0.03400, saving model to ./Models/model_1_06_0.0340.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03400 to 0.03082, saving model to ./Models/model_1_09_0.0308.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03082 to 0.02743, saving model to ./Models/model_1_10_0.0274.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02743 to 0.02727, saving model to ./Models/model_1_11_0.0273.hdf5\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02727 to 0.02507, saving model to ./Models/model_1_13_0.0251.hdf5\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02507 to 0.02342, saving model to ./Models/model_1_18_0.0234.hdf5\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02342 to 0.02232, saving model to ./Models/model_1_19_0.0223.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02232 to 0.02165, saving model to ./Models/model_1_20_0.0217.hdf5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02165 to 0.02049, saving model to ./Models/model_1_21_0.0205.hdf5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.02049 to 0.01998, saving model to ./Models/model_1_22_0.0200.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01998 to 0.01919, saving model to ./Models/model_1_26_0.0192.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01919 to 0.01903, saving model to ./Models/model_1_27_0.0190.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01903 to 0.01743, saving model to ./Models/model_1_33_0.0174.hdf5\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01743 to 0.01632, saving model to ./Models/model_1_37_0.0163.hdf5\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "reached\n",
      "model_1_37_0.0163.hdf5\n",
      "Epoch : 37 MSE : 0.0163.hdf5 IoU : 0.911\n",
      "model_1_33_0.0174.hdf5\n",
      "Epoch : 33 MSE : 0.0174.hdf5 IoU : 0.907\n",
      "model_1_27_0.0190.hdf5\n",
      "Epoch : 27 MSE : 0.0190.hdf5 IoU : 0.902\n",
      "model_1_26_0.0192.hdf5\n",
      "Epoch : 26 MSE : 0.0192.hdf5 IoU : 0.905\n",
      "model_1_22_0.0200.hdf5\n",
      "Epoch : 22 MSE : 0.0200.hdf5 IoU : 0.902\n"
     ]
    }
   ],
   "source": [
    "#Without lr_reduce\n",
    "runModel(model,epochs=40,build=1,optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19356, saving model to ./Models/model_1_01_0.1936.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19356 to 0.11247, saving model to ./Models/model_1_02_0.1125.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11247 to 0.05304, saving model to ./Models/model_1_03_0.0530.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.05304 to 0.03660, saving model to ./Models/model_1_05_0.0366.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03660 to 0.03470, saving model to ./Models/model_1_07_0.0347.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03470 to 0.03222, saving model to ./Models/model_1_09_0.0322.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03222 to 0.03164, saving model to ./Models/model_1_10_0.0316.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03164 to 0.02872, saving model to ./Models/model_1_11_0.0287.hdf5\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.000999999977648.\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02872 to 0.02596, saving model to ./Models/model_1_16_0.0260.hdf5\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 9.99999931082e-05.\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 9.99999901978e-06.\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 9.99999883788e-07.\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 9.99999883788e-08.\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 9.99999869578e-09.\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.99999905105e-10.\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.99999860696e-11.\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Results\n",
      "model_1_37_0.0163.hdf5\n",
      "Epoch : 37 MSE : 0.0163.hdf5 IoU : 0.911\n",
      "model_1_33_0.0174.hdf5\n",
      "Epoch : 33 MSE : 0.0174.hdf5 IoU : 0.907\n",
      "model_1_27_0.0190.hdf5\n",
      "Epoch : 27 MSE : 0.0190.hdf5 IoU : 0.902\n",
      "model_1_26_0.0192.hdf5\n",
      "Epoch : 26 MSE : 0.0192.hdf5 IoU : 0.905\n",
      "model_1_22_0.0200.hdf5\n",
      "Epoch : 22 MSE : 0.0200.hdf5 IoU : 0.902\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'tensorboard' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-c169d7f68dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#With lr_reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrunModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adagrad'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-b1001a7c7f4e>\u001b[0m in \u001b[0;36mrunModel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mcheckPoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mdel\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mkeepList\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'tensorboard' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#With lr_reduce\n",
    "runModel(model,epochs=40,build=1,optimizer='adagrad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(feature_batch, feature_map, kernel_size=(3, 3),strides=(1,1), zp_flag=False):\n",
    "    if zp_flag:\n",
    "        zp = ZeroPadding2D((1,1))(feature_batch)\n",
    "    else:\n",
    "        zp = feature_batch\n",
    "    conv = Conv2D(filters=feature_map, kernel_size=kernel_size, strides=strides)(zp)\n",
    "    bn = BatchNormalization(axis=3)(conv)\n",
    "    act = LeakyReLU(1/10)(bn)\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp_img = Input(shape=(25, 25, 3))\n",
    "\n",
    "    # 51\n",
    "    conv1 = conv_layer(inp_img, 64, zp_flag=False)\n",
    "    conv2 = conv_layer(conv1, 64, zp_flag=False)\n",
    "    mp1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv2)\n",
    "    # 23\n",
    "    conv3 = conv_layer(mp1, 128, zp_flag=False)\n",
    "    conv4 = conv_layer(conv3, 256, zp_flag=False)\n",
    "    mp2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv4)\n",
    "    # 9\n",
    "#     conv7 = conv_layer(mp2, 256, zp_flag=False)\n",
    "#     conv8 = conv_layer(conv7, 256, zp_flag=False)\n",
    "#     conv9 = conv_layer(conv8, 256, zp_flag=False)\n",
    "#     mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv9)\n",
    "    # 1\n",
    "    # dense layers\n",
    "    flt = Flatten()(mp2)\n",
    "#     ds1 = dense_set(flt, 128, activation='tanh')\n",
    "#     ds2 = dense_set(flt, 64, activation='tanh')\n",
    "    ds1 = Dense(128, activation='relu')(flt)\n",
    "    ds2 = Dense(64, activation='relu')(ds1)\n",
    "    out = Dense(12, activation='linear')(ds1)\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    \n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.93989, saving model to ./Models/model_2_01_2.9399.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.93989 to 0.85498, saving model to ./Models/model_2_02_0.8550.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.85498 to 0.66507, saving model to ./Models/model_2_03_0.6651.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.66507 to 0.49039, saving model to ./Models/model_2_04_0.4904.hdf5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.49039 to 0.49036, saving model to ./Models/model_2_05_0.4904.hdf5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.49036 to 0.39523, saving model to ./Models/model_2_06_0.3952.hdf5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.39523 to 0.23748, saving model to ./Models/model_2_07_0.2375.hdf5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.23748 to 0.22092, saving model to ./Models/model_2_08_0.2209.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.22092 to 0.18630, saving model to ./Models/model_2_09_0.1863.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18630 to 0.17852, saving model to ./Models/model_2_12_0.1785.hdf5\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17852 to 0.16339, saving model to ./Models/model_2_15_0.1634.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.16339 to 0.08986, saving model to ./Models/model_2_16_0.0899.hdf5\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.08986 to 0.08810, saving model to ./Models/model_2_20_0.0881.hdf5\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.08810 to 0.08013, saving model to ./Models/model_2_26_0.0801.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.08013 to 0.06409, saving model to ./Models/model_2_27_0.0641.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.06409 to 0.06245, saving model to ./Models/model_2_30_0.0625.hdf5\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.06245 to 0.05953, saving model to ./Models/model_2_33_0.0595.hdf5\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.05953 to 0.05838, saving model to ./Models/model_2_36_0.0584.hdf5\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.05838 to 0.05390, saving model to ./Models/model_2_37_0.0539.hdf5\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.05390 to 0.04792, saving model to ./Models/model_2_39_0.0479.hdf5\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Results\n",
      "model_2_39_0.0479.hdf5\n",
      "Epoch : 39 MSE : 0.0479.hdf5 IoU : 0.851\n",
      "model_2_37_0.0539.hdf5\n",
      "Epoch : 37 MSE : 0.0539.hdf5 IoU : 0.84\n",
      "model_2_36_0.0584.hdf5\n",
      "Epoch : 36 MSE : 0.0584.hdf5 IoU : 0.824\n",
      "model_2_33_0.0595.hdf5\n",
      "Epoch : 33 MSE : 0.0595.hdf5 IoU : 0.841\n",
      "model_2_30_0.0625.hdf5\n",
      "Epoch : 30 MSE : 0.0625.hdf5 IoU : 0.811\n"
     ]
    }
   ],
   "source": [
    "#Without lr_reduce\n",
    "runModel(model,epochs=40,build=2,optimizer='adagrad',use_lr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.53406, saving model to ./Models/model_2_01_1.5341.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.53406 to 0.82706, saving model to ./Models/model_2_02_0.8271.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.82706 to 0.35821, saving model to ./Models/model_2_03_0.3582.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.35821 to 0.16510, saving model to ./Models/model_2_04_0.1651.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.16510 to 0.09787, saving model to ./Models/model_2_06_0.0979.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09787 to 0.07281, saving model to ./Models/model_2_09_0.0728.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.000999999977648.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.07281 to 0.04240, saving model to ./Models/model_2_14_0.0424.hdf5\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.04240 to 0.04232, saving model to ./Models/model_2_16_0.0423.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.04232 to 0.04152, saving model to ./Models/model_2_17_0.0415.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.04152 to 0.04149, saving model to ./Models/model_2_19_0.0415.hdf5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.04149 to 0.04107, saving model to ./Models/model_2_20_0.0411.hdf5\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.04107 to 0.04075, saving model to ./Models/model_2_22_0.0407.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.04075 to 0.04017, saving model to ./Models/model_2_24_0.0402.hdf5\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.04017 to 0.03964, saving model to ./Models/model_2_26_0.0396.hdf5\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.03964 to 0.03947, saving model to ./Models/model_2_28_0.0395.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.03947 to 0.03915, saving model to ./Models/model_2_29_0.0391.hdf5\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.03915 to 0.03913, saving model to ./Models/model_2_31_0.0391.hdf5\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.03913 to 0.03878, saving model to ./Models/model_2_34_0.0388.hdf5\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.03878 to 0.03825, saving model to ./Models/model_2_36_0.0383.hdf5\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.99999931082e-05.\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.03825 to 0.03781, saving model to ./Models/model_2_41_0.0378.hdf5\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.03781 to 0.03749, saving model to ./Models/model_2_42_0.0375.hdf5\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.03749 to 0.03745, saving model to ./Models/model_2_43_0.0374.hdf5\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.03745 to 0.03729, saving model to ./Models/model_2_45_0.0373.hdf5\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 9.99999901978e-06.\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.03729 to 0.03729, saving model to ./Models/model_2_50_0.0373.hdf5\n",
      "Results\n",
      "model_2_50_0.0373.hdf5\n",
      "Epoch : 50 MSE : 0.0373.hdf5 IoU : 0.868\n",
      "model_2_45_0.0373.hdf5\n",
      "Epoch : 45 MSE : 0.0373.hdf5 IoU : 0.868\n",
      "model_2_43_0.0374.hdf5\n",
      "Epoch : 43 MSE : 0.0374.hdf5 IoU : 0.868\n",
      "model_2_42_0.0375.hdf5\n",
      "Epoch : 42 MSE : 0.0375.hdf5 IoU : 0.868\n",
      "model_2_41_0.0378.hdf5\n",
      "Epoch : 41 MSE : 0.0378.hdf5 IoU : 0.867\n"
     ]
    }
   ],
   "source": [
    "#With lr_reduce\n",
    "runModel(model,epochs=50,build=2,optimizer='adagrad',use_lr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.37729, saving model to ./Models/model_2_01_1.3773.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.37729 to 0.68811, saving model to ./Models/model_2_02_0.6881.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.68811 to 0.48844, saving model to ./Models/model_2_03_0.4884.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.1.\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.48844 to 0.11047, saving model to ./Models/model_2_08_0.1105.hdf5\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.11047 to 0.05133, saving model to ./Models/model_2_09_0.0513.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05133 to 0.04623, saving model to ./Models/model_2_10_0.0462.hdf5\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.010000000149.\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.04623 to 0.03433, saving model to ./Models/model_2_15_0.0343.hdf5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.03433 to 0.03410, saving model to ./Models/model_2_16_0.0341.hdf5\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03410 to 0.03325, saving model to ./Models/model_2_17_0.0333.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.03325 to 0.03322, saving model to ./Models/model_2_19_0.0332.hdf5\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.03322 to 0.03271, saving model to ./Models/model_2_22_0.0327.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.03271 to 0.03242, saving model to ./Models/model_2_23_0.0324.hdf5\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.03242 to 0.03209, saving model to ./Models/model_2_25_0.0321.hdf5\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.03209 to 0.03180, saving model to ./Models/model_2_28_0.0318.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.03180 to 0.03169, saving model to ./Models/model_2_29_0.0317.hdf5\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.03169 to 0.03137, saving model to ./Models/model_2_30_0.0314.hdf5\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.000999999977648.\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.03137 to 0.03100, saving model to ./Models/model_2_35_0.0310.hdf5\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.03100 to 0.03088, saving model to ./Models/model_2_37_0.0309.hdf5\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 9.99999931082e-05.\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.99999901978e-06.\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 9.99999883788e-07.\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 9.99999883788e-08.\n",
      "Results\n",
      "model_2_37_0.0309.hdf5\n",
      "Epoch : 37 MSE : 0.0309.hdf5 IoU : 0.881\n",
      "model_2_35_0.0310.hdf5\n",
      "Epoch : 35 MSE : 0.0310.hdf5 IoU : 0.88\n",
      "model_2_30_0.0314.hdf5\n",
      "Epoch : 30 MSE : 0.0314.hdf5 IoU : 0.881\n",
      "model_2_29_0.0317.hdf5\n",
      "Epoch : 29 MSE : 0.0317.hdf5 IoU : 0.88\n",
      "model_2_28_0.0318.hdf5\n",
      "Epoch : 28 MSE : 0.0318.hdf5 IoU : 0.879\n"
     ]
    }
   ],
   "source": [
    "#With lr_reduce\n",
    "runModel(model,epochs=50,build=2,optimizer='adadelta',use_lr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp_img = Input(shape=(25, 25, 3))\n",
    "\n",
    "    # 51\n",
    "    conv1 = conv_layer(inp_img, 64, zp_flag=False)\n",
    "    conv2 = conv_layer(conv1, 128, zp_flag=False)\n",
    "    mp1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv2)\n",
    "    # 23\n",
    "    conv3 = conv_layer(mp1, 128, zp_flag=False)\n",
    "    conv4 = conv_layer(conv3, 256, zp_flag=False)\n",
    "    mp2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv4)\n",
    "    # 9\n",
    "#     conv7 = conv_layer(mp2, 256, zp_flag=False)\n",
    "#     conv8 = conv_layer(conv7, 256, zp_flag=False)\n",
    "#     conv9 = conv_layer(conv8, 256, zp_flag=False)\n",
    "#     mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv9)\n",
    "    # 1\n",
    "    # dense layers\n",
    "    flt = Flatten()(mp2)\n",
    "#     ds1 = dense_set(flt, 128, activation='tanh')\n",
    "#     ds2 = dense_set(flt, 64, activation='tanh')\n",
    "    ds1 = Dense(256, activation='relu')(flt)\n",
    "    ds2 = Dense(32, activation='relu')(ds1)\n",
    "    out = Dense(12, activation='linear')(ds1)\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    \n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roshansanthosh/.local/lib/python3.6/site-packages/keras/callbacks.py:405: RuntimeWarning: ModelCheckpoint mode <built-in function min> is unknown, fallback to auto mode.\n",
      "  RuntimeWarning)\n",
      "/home/roshansanthosh/.local/lib/python3.6/site-packages/keras/callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 7.30242, saving model to ./Models/model_3_01_7.3024.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 7.30242 to 1.08938, saving model to ./Models/model_3_02_1.0894.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.08938 to 0.40144, saving model to ./Models/model_3_03_0.4014.hdf5\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.40144\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.40144 to 0.09833, saving model to ./Models/model_3_05_0.0983.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09833\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09833\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.09833\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.09833 to 0.02809, saving model to ./Models/model_3_09_0.0281.hdf5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02809 to 0.01601, saving model to ./Models/model_3_10_0.0160.hdf5\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01601 to 0.01525, saving model to ./Models/model_3_11_0.0152.hdf5\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01525\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01525\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01525 to 0.01376, saving model to ./Models/model_3_14_0.0138.hdf5\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01376\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01376 to 0.01327, saving model to ./Models/model_3_16_0.0133.hdf5\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01327\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01327 to 0.01177, saving model to ./Models/model_3_18_0.0118.hdf5\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01177\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01177\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01177\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01177 to 0.00808, saving model to ./Models/model_3_22_0.0081.hdf5\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.00808\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.00808\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00808\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00808 to 0.00797, saving model to ./Models/model_3_26_0.0080.hdf5\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.00797 to 0.00793, saving model to ./Models/model_3_27_0.0079.hdf5\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00793 to 0.00790, saving model to ./Models/model_3_28_0.0079.hdf5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00790 to 0.00785, saving model to ./Models/model_3_29_0.0078.hdf5\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00785\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00785\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00785\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 2.000000222324161e-07.\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.00785\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00785\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00785\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-08.\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.00785 to 0.00782, saving model to ./Models/model_3_36_0.0078.hdf5\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-09.\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-10.\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-11.\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-12.\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00782\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00782 to 0.00778, saving model to ./Models/model_3_51_0.0078.hdf5\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 2.000000208848829e-13.\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 2.0000002359538835e-14.\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 2.000000303716519e-15.\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 2.0000002190132243e-16.\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 2.0000001660736652e-17.\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00778\n",
      "\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 2.0000001329864408e-18.\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00778\n",
      "Results\n",
      "model_3_51_0.0078.hdf5\n",
      "Epoch : 51 MSE : 0.0078.hdf5 IoU : 0.933\n",
      "model_3_29_0.0078.hdf5\n",
      "Epoch : 29 MSE : 0.0078.hdf5 IoU : 0.932\n",
      "model_3_36_0.0078.hdf5\n",
      "Epoch : 36 MSE : 0.0078.hdf5 IoU : 0.932\n",
      "model_3_28_0.0079.hdf5\n",
      "Epoch : 28 MSE : 0.0079.hdf5 IoU : 0.932\n",
      "model_3_27_0.0079.hdf5\n",
      "Epoch : 27 MSE : 0.0079.hdf5 IoU : 0.931\n"
     ]
    }
   ],
   "source": [
    "#With lr_reduce\n",
    "runModel(model,epochs=70,build=3,optimizer='adadelta',use_lr=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp_img = Input(shape=(25, 25, 3))\n",
    "\n",
    "    # 51\n",
    "    conv1 = conv_layer(inp_img, 256, zp_flag=False)\n",
    "    conv2 = conv_layer(conv1, 128, zp_flag=False)\n",
    "    mp1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv2)\n",
    "    # 23\n",
    "    conv3 = conv_layer(mp1, 128, zp_flag=False)\n",
    "    conv4 = conv_layer(conv3, 64, zp_flag=False)\n",
    "    mp2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(conv4)\n",
    "    # 9\n",
    "#     conv7 = conv_layer(mp2, 256, zp_flag=False)\n",
    "#     conv8 = conv_layer(conv7, 256, zp_flag=False)\n",
    "#     conv9 = conv_layer(conv8, 256, zp_flag=False)\n",
    "#     mp3 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(conv9)\n",
    "    # 1\n",
    "    # dense layers\n",
    "    flt = Flatten()(mp2)\n",
    "#     ds1 = dense_set(flt, 128, activation='tanh')\n",
    "#     ds2 = dense_set(flt, 64, activation='tanh')\n",
    "    ds1 = Dense(256, activation='relu')(flt)\n",
    "    ds2 = Dense(32, activation='relu')(ds1)\n",
    "    out = Dense(12, activation='linear')(ds1)\n",
    "\n",
    "    model = Model(inputs=inp_img, outputs=out)\n",
    "    \n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model=get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.27731, saving model to ./Models/model_4_01_4.2773.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 4.27731 to 3.54924, saving model to ./Models/model_4_05_3.5492.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.54924 to 2.22029, saving model to ./Models/model_4_07_2.2203.hdf5\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.22029 to 0.89899, saving model to ./Models/model_4_10_0.8990.hdf5\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.89899 to 0.83516, saving model to ./Models/model_4_12_0.8352.hdf5\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.83516 to 0.24244, saving model to ./Models/model_4_14_0.2424.hdf5\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.24244 to 0.12248, saving model to ./Models/model_4_17_0.1225.hdf5\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.1.\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.12248 to 0.03282, saving model to ./Models/model_4_22_0.0328.hdf5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.03282 to 0.02616, saving model to ./Models/model_4_23_0.0262.hdf5\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.02616 to 0.02598, saving model to ./Models/model_4_27_0.0260.hdf5\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.02598 to 0.02376, saving model to ./Models/model_4_30_0.0238.hdf5\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.02376 to 0.02212, saving model to ./Models/model_4_33_0.0221.hdf5\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.010000000149.\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.02212 to 0.02044, saving model to ./Models/model_4_38_0.0204.hdf5\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.02044 to 0.02025, saving model to ./Models/model_4_40_0.0202.hdf5\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.02025 to 0.01992, saving model to ./Models/model_4_41_0.0199.hdf5\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.000999999977648.\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.99999931082e-05.\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Results\n",
      "model_4_41_0.0199.hdf5\n",
      "Epoch : 41 MSE : 0.0199.hdf5 IoU : 0.896\n",
      "model_4_40_0.0202.hdf5\n",
      "Epoch : 40 MSE : 0.0202.hdf5 IoU : 0.894\n",
      "model_4_38_0.0204.hdf5\n",
      "Epoch : 38 MSE : 0.0204.hdf5 IoU : 0.894\n",
      "model_4_33_0.0221.hdf5\n",
      "Epoch : 33 MSE : 0.0221.hdf5 IoU : 0.889\n",
      "model_4_30_0.0238.hdf5\n",
      "Epoch : 30 MSE : 0.0238.hdf5 IoU : 0.885\n"
     ]
    }
   ],
   "source": [
    "#With lr_reduce\n",
    "runModel(model,epochs=50,build=4,optimizer='adadelta',use_lr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.06662, saving model to ./Models/model_4_01_2.0666.hdf5\n",
      "\n",
      "Epoch 00002: val_loss did not improve\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "\n",
      "Epoch 00005: val_loss improved from 2.06662 to 0.68695, saving model to ./Models/model_4_05_0.6870.hdf5\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.68695 to 0.49931, saving model to ./Models/model_4_09_0.4993.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.000200000009499.\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.49931 to 0.02366, saving model to ./Models/model_4_14_0.0237.hdf5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02366 to 0.01723, saving model to ./Models/model_4_15_0.0172.hdf5\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01723 to 0.01282, saving model to ./Models/model_4_19_0.0128.hdf5\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.00000009499e-05.\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.01282 to 0.01127, saving model to ./Models/model_4_24_0.0113.hdf5\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01127 to 0.01062, saving model to ./Models/model_4_25_0.0106.hdf5\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.00000013137e-06.\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 2.00000022232e-07.\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 2.00000016548e-08.\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.00000016548e-09.\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 2.00000016548e-10.\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.01062 to 0.01059, saving model to ./Models/model_4_42_0.0106.hdf5\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 2.00000016548e-11.\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 2.00000016548e-12.\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n",
      "Results\n",
      "model_4_25_0.0106.hdf5\n",
      "Epoch : 25 MSE : 0.0106.hdf5 IoU : 0.922\n",
      "model_4_42_0.0106.hdf5\n",
      "Epoch : 42 MSE : 0.0106.hdf5 IoU : 0.921\n",
      "model_4_24_0.0113.hdf5\n",
      "Epoch : 24 MSE : 0.0113.hdf5 IoU : 0.917\n",
      "model_4_19_0.0128.hdf5\n",
      "Epoch : 19 MSE : 0.0128.hdf5 IoU : 0.915\n",
      "model_4_15_0.0172.hdf5\n",
      "Epoch : 15 MSE : 0.0172.hdf5 IoU : 0.895\n"
     ]
    }
   ],
   "source": [
    "#With adam hardcoded\n",
    "runModel(model,epochs=50,build=4,optimizer='adadelta',use_lr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/home/rsk/Documents/Projects/YOLO/MultiClass/Models/model_4_25_0.0106.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_model('/home/rsk/Documents/Projects/YOLO/MultiClass/Models/model_2_30_0.0314.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numAnchors=2\n",
    "anchorLength=6\n",
    "\n",
    "boxLimits = [[0,0,12,25],\n",
    "             [12,0,25,25]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  addRect(anchorLength,boxLimits,pred,color='blue'):\n",
    "    \n",
    "    rectList = []\n",
    "    \n",
    "    for k in range(len(boxLimits)):\n",
    "        box = boxLimits[k]\n",
    "        predBox = pred[0][k*anchorLength:(k*anchorLength+4)]\n",
    "        predBoxClass = pred[0][k*anchorLength+4:(k*anchorLength+6)]\n",
    "        \n",
    "        if predBoxClass[0]> predBoxClass[1]:\n",
    "            color='blue'\n",
    "        else:\n",
    "            color ='red'\n",
    "  \n",
    "        rect = Rectangle((predBox[0]+box[0]-0.5,predBox[1]+box[1]-0.5),predBox[2]+1, predBox[3]+1,fill=False,edgecolor=color,\n",
    "                     linewidth=2)\n",
    "        rectList.append(rect)\n",
    "        \n",
    "    return(rectList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabelProb(pred,truth):\n",
    "    \n",
    "    softmax_results = []\n",
    "    \n",
    "    for k in range(len(boxLimits)):\n",
    "        anchor_pred = pred[0][(k*anchorLength+4): (k*anchorLength+6) ]\n",
    "        print(anchor_pred)\n",
    "        truth_pred = truth[0][(k*anchorLength+4): (k*anchorLength+6) ]\n",
    "        \n",
    "        result = softmax(anchor_pred)\n",
    "        \n",
    "        predLabel = np.argmax(result)\n",
    "        truthLabel = np.argmax(truth_pred)\n",
    "        \n",
    "        softmax_results.append(result)\n",
    "        \n",
    "    return(softmax_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSample(obs,modelList,numAnchors = 2):\n",
    "    \n",
    "    if obs>=len(testX):\n",
    "        print(\"Out of bounds\")\n",
    "        \n",
    "    sample = testX[obs]\n",
    "    \n",
    "    sample = sample.reshape((1,25,25,3))\n",
    "    sample = sample/255.\n",
    "    truth = [testy[obs]]\n",
    "    \n",
    "    IoU1 = getIoU(modelList[0][0], sample, truth,rescale=False)\n",
    "    IoU2 = getIoU(modelList[1][0], sample, truth,rescale=False)\n",
    "    \n",
    "    pred1 = modelList[0][0].predict(sample)\n",
    "    pred2 = modelList[1][0].predict(sample)\n",
    "    \n",
    "    \n",
    "    softmax1 = getLabelProb(pred1,truth)\n",
    "    softmax2 = getLabelProb(pred2,truth)\n",
    "    \n",
    "    factor=0.2\n",
    "    matplotlib.rcParams['figure.figsize'] = [40*factor,75*factor]\n",
    "    \n",
    "    \n",
    "    fig,ax = plt.subplots(1)\n",
    "    \n",
    "    ax.imshow(sample[0,:,:,:])\n",
    "    \n",
    "    rectList1 = addRect(anchorLength,boxLimits,pred1,modelList[0][1])\n",
    "    rectList2 = addRect(anchorLength,boxLimits,pred2,modelList[1][1])\n",
    "    \n",
    "    for rec in rectList1:\n",
    "        ax.add_patch(rec)\n",
    "    for rec in rectList2:\n",
    "        ax.add_patch(rec)\n",
    "        \n",
    "\n",
    "    \n",
    "    print(\"Truth : {}\".format(truth[0]))\n",
    "    print(\"Pred1 : {}\".format(pred1))\n",
    "    print(\"Pred2 : {}\".format(pred2))\n",
    "    \n",
    "    print(\"IoU1 : {} IoU2 : {}\".format(IoU1,IoU2))\n",
    "    print(\"Softmax Label 1 : {}\".format(softmax1))\n",
    "    print(\"Softmax Label 2 : {}\".format(softmax2))\n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01303518  1.0101451 ]\n",
      "[ 1.0228567  -0.02027929]\n",
      "[0.02493751 1.0983742 ]\n",
      "[0.8726274  0.05090879]\n",
      "Truth : [ 7  1  4  4  0  1  8  2  3 16  1  0]\n",
      "Pred1 : [[ 6.9415421e+00  9.9285376e-01  4.1061721e+00  4.0263219e+00\n",
      "  -1.3035178e-02  1.0101451e+00  7.8868227e+00  1.9874225e+00\n",
      "   3.0137141e+00  1.5910894e+01  1.0228567e+00 -2.0279288e-02]]\n",
      "Pred2 : [[ 6.861466    1.1331781   4.0214953   4.1073804   0.02493751  1.0983742\n",
      "   7.8818426   1.525068    3.1945374  16.549389    0.8726274   0.05090879]]\n",
      "IoU1 : 0.958092242834 IoU2 : 0.903896053935\n",
      "Softmax Label 1 : [array([0.26440838, 0.7355916 ], dtype=float32), array([0.7394546 , 0.26054534], dtype=float32)]\n",
      "Softmax Label 2 : [array([0.25475007, 0.7452499 ], dtype=float32), array([0.69460106, 0.305399  ], dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAHhCAYAAAC/Y81KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAD9hJREFUeJzt3U/o5Hd9x/HXu1m9qIdIfl1CTLpWQmEvjeVHEColYivRS/Qi5lByENaDgoKX4EUvBS9qLyJEDMnBPwhqzSG0hiCkhSL+lKDRVBJkxSxrdoMHvUn03cPOtr+m2ewvv5nfzDszjweEmfnO7G/e+2U2z9/nO/+quwMAbNafbXoAAECQAWAEQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABjg1Drv7KabbuozZ86s8y4BYGPOnz+fF154oY5y27UG+cyZMzk4OFjnXQLAxuzv7x/5tg5ZA8AAggwAAwgyAAwgyAAwwFJBrqq7q+oXVfVsVd2/qqEAYNccO8hVdUOSLyZ5b5KzSe6tqrOrGgwAdskyK+Q7kzzb3b/s7j8k+UaSe1YzFgDslmWCfEuSXx+6/Nxi2/9RVeeq6qCqDi5fvrzE3QHA9jrxF3V19wPdvd/d+3t7eyd9dwDwmrRMkC8kufXQ5bcstgEAr9IyQf5hktur6q1V9fokH0ryyGrGAoDdcuzPsu7uF6vqY0n+LckNSR7s7p+tbDIA2CFLfblEdz+a5NEVzQIAO8sndQHAAIIMAAOs9fuQ2SF1pO/jZpW6Nz0BsAQrZAAYwAqZkzVs1VYrWrn3pL+XoxGwFQSZ1XppHIbFYmUZnfL3mvSLAbAUh6wBYAArZE7WsBXc1hyynrJCB1bGChkABhBkABhAkAFgAEEGgAG8qAtgh3g94Ku3rtdwWiEDwABWyAA7aNPv3HstWPfRBCtkABhAkAFgAEEGgAEEGQAGEGQAGMCrrAF2kPcjv7JNvApdkHlNWNW3NK3K1nxrFPCyrvwbX++/T0EG2EFXfxec9svu5m3ul2TPIQPAAIIMAAMIMgAMIMgAMIAgA8AAggwAAwgyAAwgyAAwgCADwACCDAADCDIADCDIADCAIAPAAIIMAAMIMgAMIMgAMMCpTQ/AdvPl56/suPvn6leoV9UGv04dWCUrZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABji16QHYbt29kp9TVSv5OdMce/8s9kd3/8954LXNChkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGOLXpAeAounslP6eqVvJzVjUPwFVWyAAwgCADwACCDAADCDIADCDIADDAUq+yrqrzSX6f5I9JXuzu/VUMBQC7ZhVve3pXd7+wgp8DADvLIWsAGGDZIHeS71XVj6rq3CoGAoBdtOwh63d294Wq+vMkj1XVf3X3E4dvsAj1uSS57bbblrw7ANhOS62Qu/vC4vRSku8kufNlbvNAd+939/7e3t4ydwcAW+vYQa6qN1TVm66eT/KeJE+tajAA2CXLHLI+neQ7iw/rP5Xka939ryuZCgB2zLGD3N2/TPLXK5wFAHaWtz0BwACCDAADCDIADLCKj86Ea7vyor8xelU/aMrfa8ocwNKskAFgACtkTkavbC3Ky7m6MrafYWtYIQPAAFbInAzPbQK8KlbIADCAFTKr5TlNgGOxQgaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGuG6Qq+rBqrpUVU8d2vbmqnqsqp5ZnN54smMCwHY7ygr5oSR3v2Tb/Uke7+7bkzy+uAwAHNN1g9zdTyT57Us235Pk4cX5h5O8f8VzAcBOOe5zyKe7++Li/G+SnF7RPACwk5Z+UVd3d5K+1vVVda6qDqrq4PLly8veHQBspeMG+fmqujlJFqeXrnXD7n6gu/e7e39vb++YdwcA2+24QX4kyX2L8/cl+e5qxgGA3XSUtz19Pcl/Jvmrqnquqj6c5LNJ/qGqnkny94vLAMAxnbreDbr73mtc9e4VzwIAO8sndQHAAIIMAAMIMgAMIMgAMIAgA8AAggwAAwgyAAwgyAAwgCADwACCDAADCDIADCDIADCAIAPAAIIMAAMIMgAMIMgAMIAgA8AAggwAAwgyAAwgyAAwgCADwACCDAADCDIADCDIADCAIAPAAIIMAAMIMgAMIMgAMIAgA8AAggwAAwgyAAwgyAAwgCADwACCDAADCDIADCDIADCAIAPAAIIMAAMIMgAMIMgAMIAgA8AAggwAAwgyAAwgyAAwgCADwACCDAADCDIADCDIADCAIAPAAIIMAAMIMgAMIMgAMIAgA8AAggwAAwgyAAwgyAAwgCADwACCDAADCDIADCDIADCAIAPAAIIMAAMIMgAMIMgAMIAgA8AAggwAAwgyAAwgyAAwgCADwACCDAADCDIADCDIADCAIAPAAIIMAAMIMgAMIMgAMIAgA8AAggwAAwgyAAwgyAAwwHWDXFUPVtWlqnrq0LbPVNWFqnpy8d/7TnZMANhuR1khP5Tk7pfZ/oXuvmPx36OrHQsAdst1g9zdTyT57RpmAYCdtcxzyB+rqp8sDmnfuLKJAGAHHTfIX0rytiR3JLmY5HPXumFVnauqg6o6uHz58jHvDgC227GC3N3Pd/cfu/tPSb6c5M5XuO0D3b3f3ft7e3vHnRMAttqxglxVNx+6+IEkT13rtgDA9Z263g2q6utJ7kpyU1U9l+TTSe6qqjuSdJLzST5ygjMCwNa7bpC7+96X2fyVE5gFAHaWT+oCgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAY4NSmBwBg/aqunutNjsEhVsgAMIAVMsAO6sXCuP53qcyGCTLADnLIeh6HrAFgACtkgB3SFsRjWSEDwACCDAADCDIADCDIADCAIAPAAIIMAAMIMgAMIMgAMIAgA8AAggwAAwgyAAwgyAAwgCADwACCDAADCDIADCDIADCAIAPAAIIMAAMIMgAMIMgAMMB1g1xVt1bV96vq51X1s6r6+GL7m6vqsap6ZnF648mPCwDb6Sgr5BeTfLK7zyZ5R5KPVtXZJPcneby7b0/y+OIyAHAM1w1yd1/s7h8vzv8+ydNJbklyT5KHFzd7OMn7T2pIANh2r+o55Ko6k+TtSX6Q5HR3X1xc9Zskp6/xZ85V1UFVHVy+fHmJUQFgex05yFX1xiTfSvKJ7v7d4eu6u5P0y/257n6gu/e7e39vb2+pYQFgWx0pyFX1ulyJ8Ve7+9uLzc9X1c2L629OculkRgSA7XeUV1lXkq8kebq7P3/oqkeS3Lc4f1+S765+PADYDaeOcJu/TfKPSX5aVU8utn0qyWeTfLOqPpzkV0k+eDIjAsD2u26Qu/s/ktQ1rn73ascBgN3kk7oAYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABhBkABhAkAFgAEEGgAEEGQAGEGQAGECQAWAAQQaAAQQZAAYQZAAYQJABYABBBoABBBkABqjuXt+dVV1O8qvr3OymJC+sYZxdZh+fPPt4Peznk2cfL+cvunvvKDdca5CPoqoOunt/03NsM/v45NnH62E/nzz7eH0csgaAAQQZAAaYGOQHNj3ADrCPT559vB7288mzj9dk3HPIALCLJq6QAWDnjAlyVd1dVb+oqmer6v5Nz7Otqup8Vf20qp6sqoNNz7MNqurBqrpUVU8d2vbmqnqsqp5ZnN64yRlf666xjz9TVRcWj+Unq+p9m5zxta6qbq2q71fVz6vqZ1X18cV2j+U1GRHkqrohyReTvDfJ2ST3VtXZzU611d7V3Xd4K8PKPJTk7pdsuz/J4919e5LHF5c5vofy//dxknxh8Vi+o7sfXfNM2+bFJJ/s7rNJ3pHko4v/D3ssr8mIICe5M8mz3f3L7v5Dkm8kuWfDM8GRdPcTSX77ks33JHl4cf7hJO9f61Bb5hr7mBXq7ovd/ePF+d8neTrJLfFYXpspQb4lya8PXX5usY3V6yTfq6ofVdW5TQ+zxU5398XF+d8kOb3JYbbYx6rqJ4tD2g6lrkhVnUny9iQ/iMfy2kwJMuvzzu7+m1x5euCjVfV3mx5o2/WVtzJ4O8PqfSnJ25LckeRiks9tdpztUFVvTPKtJJ/o7t8dvs5j+WRNCfKFJLceuvyWxTZWrLsvLE4vJflOrjxdwOo9X1U3J8ni9NKG59k63f18d/+xu/+U5MvxWF5aVb0uV2L81e7+9mKzx/KaTAnyD5PcXlVvrarXJ/lQkkc2PNPWqao3VNWbrp5P8p4kT73yn+KYHkly3+L8fUm+u8FZttLVSCx8IB7LS6mqSvKVJE939+cPXeWxvCZjPhhk8ZaFf05yQ5IHu/ufNjzS1qmqv8yVVXGSnEryNft5eVX19SR35cq34jyf5NNJ/iXJN5PclivfcPbB7vaipGO6xj6+K1cOV3eS80k+cui5Tl6lqnpnkn9P8tMkf1ps/lSuPI/ssbwGY4IMALtsyiFrANhpggwAAwgyAAwgyAAwgCADwACCDAADCDIADCDIADDAfwMlpYvCAwrI/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testSample(45,[[model,'red'],[model1,'blue']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### VideoFrame Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testSample2(filename,modelList,numAnchors = 2):\n",
    "    \n",
    "  \n",
    "    sample = read_img(filename,(25,25))\n",
    "    \n",
    "    sample = sample.reshape((1,25,25,3))\n",
    "    sample = sample/255.\n",
    "    \n",
    "    pred1 = modelList[0][0].predict(sample)\n",
    "    \n",
    "    factor=0.2\n",
    "    matplotlib.rcParams['figure.figsize'] = [40*factor,75*factor]\n",
    "    \n",
    "    \n",
    "    fig,ax = plt.subplots(1)\n",
    "    \n",
    "    ax.imshow(sample[0,:,:,:])\n",
    "    \n",
    "    rectList1 = addRect(anchorLength,boxLimits,pred1,modelList[0][1])\n",
    "    \n",
    "    \n",
    "    for rec in rectList1:\n",
    "        ax.add_patch(rec)\n",
    "        \n",
    "\n",
    "    return(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x1080 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e = testSample2('/home/rsk/Documents/Projects/YOLO/MultiClass/VideoImageFolder/img56.png',[[model,'blue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n",
      "1825\n",
      "1826\n",
      "1827\n",
      "1828\n",
      "1829\n",
      "1830\n",
      "1831\n",
      "1832\n",
      "1833\n",
      "1834\n",
      "1835\n",
      "1836\n",
      "1837\n",
      "1838\n",
      "1839\n",
      "1840\n",
      "1841\n",
      "1842\n",
      "1843\n",
      "1844\n",
      "1845\n",
      "1846\n",
      "1847\n",
      "1848\n",
      "1849\n",
      "1850\n",
      "1851\n",
      "1852\n",
      "1853\n",
      "1854\n",
      "1855\n",
      "1856\n",
      "1857\n",
      "1858\n",
      "1859\n",
      "1860\n",
      "1861\n",
      "1862\n",
      "1863\n",
      "1864\n",
      "1865\n",
      "1866\n",
      "1867\n",
      "1868\n",
      "1869\n",
      "1870\n",
      "1871\n",
      "1872\n",
      "1873\n",
      "1874\n",
      "1875\n",
      "1876\n",
      "1877\n",
      "1878\n",
      "1879\n",
      "1880\n",
      "1881\n",
      "1882\n",
      "1883\n",
      "1884\n",
      "1885\n",
      "1886\n",
      "1887\n",
      "1888\n",
      "1889\n",
      "1890\n",
      "1891\n",
      "1892\n",
      "1893\n",
      "1894\n",
      "1895\n",
      "1896\n",
      "1897\n",
      "1898\n",
      "1899\n",
      "1900\n",
      "1901\n",
      "1902\n",
      "1903\n",
      "1904\n",
      "1905\n",
      "1906\n",
      "1907\n",
      "1908\n",
      "1909\n",
      "1910\n",
      "1911\n",
      "1912\n",
      "1913\n",
      "1914\n",
      "1915\n",
      "1916\n",
      "1917\n",
      "1918\n",
      "1919\n",
      "1920\n",
      "1921\n",
      "1922\n",
      "1923\n",
      "1924\n",
      "1925\n",
      "1926\n",
      "1927\n",
      "1928\n",
      "1929\n",
      "1930\n",
      "1931\n",
      "1932\n",
      "1933\n",
      "1934\n",
      "1935\n",
      "1936\n",
      "1937\n",
      "1938\n",
      "1939\n",
      "1940\n",
      "1941\n",
      "1942\n",
      "1943\n",
      "1944\n",
      "1945\n",
      "1946\n",
      "1947\n",
      "1948\n",
      "1949\n",
      "1950\n",
      "1951\n",
      "1952\n",
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n",
      "1970\n",
      "1971\n",
      "1972\n",
      "1973\n",
      "1974\n",
      "1975\n",
      "1976\n",
      "1977\n",
      "1978\n",
      "1979\n",
      "1980\n",
      "1981\n",
      "1982\n",
      "1983\n",
      "1984\n",
      "1985\n",
      "1986\n",
      "1987\n",
      "1988\n",
      "1989\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/rsk/Documents/Projects/YOLO/MultiClass/VideoImageFolderPreds\")\n",
    "\n",
    "for i in range(1500,2000):\n",
    "    filename = '/home/rsk/Documents/Projects/YOLO/MultiClass/VideoImageFolder/img'+str(i)+'.png'\n",
    "    \n",
    "    pred = testSample2(filename,[[model,'blue']])\n",
    "    print(i)\n",
    "    \n",
    "    pred.savefig('pred'+str(i)+'.png')\n",
    "    \n",
    "    plt.close(pred)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
